{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from typing import Tuple\n",
    "\n",
    "class AdjacencyMatrixGenerator:\n",
    "    \"\"\"\n",
    "    A class to generate adjacency matrices for directed and undirected graphs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.matrices = []\n",
    "        self.labels = []\n",
    "        \n",
    "    def generate_symmetric_matrix(self, n: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate a symmetric adjacency matrix (undirected graph).\n",
    "        \n",
    "        Args:\n",
    "            n (int): Size of the matrix (n x n)\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Symmetric adjacency matrix\n",
    "        \"\"\"\n",
    "        # Generate random upper triangular matrix\n",
    "        matrix = np.random.randint(0, 2, size=(n, n))\n",
    "        \n",
    "        # Make it symmetric by copying upper triangle to lower triangle\n",
    "        matrix = np.triu(matrix) + np.triu(matrix, 1).T\n",
    "        \n",
    "        # Ensure diagonal is 0 (no self-loops)\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    def generate_non_symmetric_matrix(self, n: int) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate a non-symmetric adjacency matrix (directed graph).\n",
    "        \n",
    "        Args:\n",
    "            n (int): Size of the matrix (n x n)\n",
    "            \n",
    "        Returns:\n",
    "            np.ndarray: Non-symmetric adjacency matrix\n",
    "        \"\"\"\n",
    "        # Generate random matrix\n",
    "        matrix = np.random.randint(0, 2, size=(n, n))\n",
    "        \n",
    "        # Ensure diagonal is 0 (no self-loops)\n",
    "        np.fill_diagonal(matrix, 0)\n",
    "        \n",
    "        # Ensure it's actually non-symmetric by modifying at least one element\n",
    "        # if the random matrix happens to be symmetric\n",
    "        if np.array_equal(matrix, matrix.T):\n",
    "            # Find a position to make asymmetric\n",
    "            for i in range(n):\n",
    "                for j in range(i+1, n):\n",
    "                    if matrix[i, j] == matrix[j, i]:\n",
    "                        matrix[i, j] = 1 - matrix[i, j]  # Flip the bit\n",
    "                        break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    def generate_dataset(self, n: int, num_symmetric: int, num_non_symmetric: int):\n",
    "        \"\"\"\n",
    "        Generate a dataset of adjacency matrices.\n",
    "        \n",
    "        Args:\n",
    "            n (int): Size of each matrix\n",
    "            num_symmetric (int): Number of symmetric matrices to generate\n",
    "            num_non_symmetric (int): Number of non-symmetric matrices to generate\n",
    "        \"\"\"\n",
    "        self.matrices = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Generate symmetric matrices (label = 0 for undirected)\n",
    "        for _ in range(num_symmetric):\n",
    "            matrix = self.generate_symmetric_matrix(n)\n",
    "            self.matrices.append(matrix)\n",
    "            self.labels.append(0)  # 0 for undirected/symmetric\n",
    "            \n",
    "        # Generate non-symmetric matrices (label = 1 for directed)\n",
    "        for _ in range(num_non_symmetric):\n",
    "            matrix = self.generate_non_symmetric_matrix(n)\n",
    "            self.matrices.append(matrix)\n",
    "            self.labels.append(1)  # 1 for directed/non-symmetric\n",
    "    \n",
    "    def save_to_pickle(self, filename: str):\n",
    "        \"\"\"\n",
    "        Save the generated matrices and labels to a pickle file.\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Name of the file to save to\n",
    "        \"\"\"\n",
    "        data = {\n",
    "            'matrices': self.matrices,\n",
    "            'labels': self.labels,\n",
    "            'matrix_size': len(self.matrices[0]) if self.matrices else 0\n",
    "        }\n",
    "        \n",
    "        with open(filename, 'wb') as f:\n",
    "            pickle.dump(data, f)\n",
    "        \n",
    "        print(f\"Saved {len(self.matrices)} matrices to {filename}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    def load_from_pickle(self, filename: str):\n",
    "        \"\"\"\n",
    "        Load matrices and labels from a pickle file.\n",
    "        \n",
    "        Args:\n",
    "            filename (str): Name of the file to load from\n",
    "        \"\"\"\n",
    "        with open(filename, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        self.matrices = data['matrices']\n",
    "        self.labels = data['labels']\n",
    "        \n",
    "        print(f\"Loaded {len(self.matrices)} matrices from {filename}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_flattened_data(self) -> Tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Get matrices flattened into vectors for neural network input.\n",
    "        \n",
    "        Returns:\n",
    "            Tuple[np.ndarray, np.ndarray]: Flattened matrices and labels\n",
    "        \"\"\"\n",
    "        if not self.matrices:\n",
    "            return np.array([]), np.array([])\n",
    "        \n",
    "        flattened_matrices = np.array([matrix.flatten() for matrix in self.matrices])\n",
    "        labels_array = np.array(self.labels)\n",
    "        \n",
    "        return flattened_matrices, labels_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luis Hernandez, Roberto Palacios\n",
    "# Note: this code was partially generated by AI (Grok 3)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to generate a dataset of 4x4 adjacency matrices for directed and undirected graphs\n",
    "def generate_adjacency_matrices(num_samples, nodes=4):\n",
    "    # Initialize lists to store flattened matrices and their corresponding labels\n",
    "    matrices = []\n",
    "    labels = []\n",
    "\n",
    "    # Generate undirected graphs (symmetric matrices) for half the samples\n",
    "    for _ in range(num_samples // 2):\n",
    "        # Create a 4x4 zero matrix\n",
    "        matrix = np.zeros((nodes, nodes))\n",
    "        # Fill upper triangle randomly and mirror to lower triangle for symmetry\n",
    "        for i in range(nodes):\n",
    "            for j in range(i + 1, nodes):\n",
    "                if np.random.random() > 0.5:  # 50% chance of an edge\n",
    "                    matrix[i][j] = 1\n",
    "                    matrix[j][i] = 1  # Ensure symmetry for undirected graphs\n",
    "        # Flatten the 4x4 matrix into a 16-element vector\n",
    "        matrices.append(matrix.flatten())\n",
    "        # Label as 0 for undirected graphs\n",
    "        labels.append([0])\n",
    "\n",
    "    # Generate directed graphs (asymmetric matrices) for the other half\n",
    "    for _ in range(num_samples // 2):\n",
    "        # Create a 4x4 zero matrix\n",
    "        matrix = np.zeros((nodes, nodes))\n",
    "        # Fill randomly without enforcing symmetry\n",
    "        for i in range(nodes):\n",
    "            for j in range(nodes):\n",
    "                if i != j and np.random.random() > 0.5:  # Avoid self-loops\n",
    "                    matrix[i][j] = 1\n",
    "        # Flatten the 4x4 matrix into a 16-element vector\n",
    "        matrices.append(matrix.flatten())\n",
    "        # Label as 1 for directed graphs\n",
    "        labels.append([1])\n",
    "\n",
    "    # Convert lists to numpy arrays for efficient computation\n",
    "    return np.array(matrices), np.array(labels)\n",
    "\n",
    "# Sigmoid activation function to map values to (0, 1)\n",
    "def sigmoid(x):\n",
    "    # Compute 1 / (1 + e^-x) element-wise\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Derivative of sigmoid for backpropagation, note that this takes in activated output and not raw input\n",
    "def sigmoid_derivative_from_output(x):\n",
    "    # Compute sigmoid(x) * (1 - sigmoid(x)) for the gradient\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Neural Network class to classify graphs\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        # Initializing weights and biases with small random values\n",
    "        # input_size = 16 (4x4 flattened), hidden_size = number of hidden neurons, output_size = 1\n",
    "        self.W1 = np.random.randn(input_size, hidden_size) * 0.01  # Input to hidden weights\n",
    "        self.b1 = np.zeros((1, hidden_size))  # Hidden layer biases\n",
    "        self.W2 = np.random.randn(hidden_size, output_size) * 0.01  # Hidden to output weights\n",
    "        self.b2 = np.zeros((1, output_size))  # Output biases\n",
    "    # Perform forward propagation through the network\n",
    "    def forward(self, X):\n",
    "        # Compute hidden layer input: X * W1 + b1\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        # Apply sigmoid activation to hidden layer\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "        # Compute output layer input: a1 * W2 + b2\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        # Apply sigmoid activation to output layer\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        # Return final output\n",
    "        return self.a2\n",
    "\n",
    "    # Backward propagation to update weights & biases\n",
    "    def backward(self, X, y, output, learning_rate):\n",
    "        # Compute error at output layer, true means predicted\n",
    "        self.error = y - output\n",
    "        # Compute output layer gradient, error * sigmoid derivative\n",
    "        self.delta2 = self.error * sigmoid_derivative_from_output(output)\n",
    "\n",
    "        # Propagate error to hidden layer: delta2 * W2^T\n",
    "        self.error_hidden = np.dot(self.delta2, self.W2.T)\n",
    "        # Compute hidden layer gradient: error_hidden * sigmoid derivative\n",
    "        self.delta1 = self.error_hidden * sigmoid_derivative_from_output(self.a1)\n",
    "\n",
    "        # Update weights & biases using gradient descent\n",
    "        self.W2 += learning_rate * np.dot(self.a1.T, self.delta2)  # Update hidden to output weights\n",
    "        self.b2 += learning_rate * np.sum(self.delta2, axis=0, keepdims=True)  # Update output biases\n",
    "        self.W1 += learning_rate * np.dot(X.T, self.delta1)  # Update input to hidden weights\n",
    "        self.b1 += learning_rate * np.sum(self.delta1, axis=0, keepdims=True)  # Update hidden biases\n",
    "\n",
    "    # Train the network for the specified number of epochs\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        errors = []  # List to store mean squared error per epoch\n",
    "        for epoch in range(epochs):\n",
    "            # Forward pass to get predictions\n",
    "            output = self.forward(X)\n",
    "            # Backward pass to update parameters\n",
    "            self.backward(X, y, output, learning_rate)\n",
    "            # Compute mean squared error for this epoch\n",
    "            mse = np.mean(np.square(y - output))\n",
    "            errors.append(mse)\n",
    "            # Print progress every 1000 epochs\n",
    "            if epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, MSE: {mse:.6f}\")\n",
    "        # Return list of errors for plotting\n",
    "        return errors\n",
    "\n",
    "# Hyperparameters for neural network\n",
    "input_size = 16  # 4x4 matrix flattened into a 16-element vector\n",
    "hidden_size = 32  # Number of neurons in the hidden layer, adjustable\n",
    "output_size = 1   # Single output neuron: 0 for undirected, 1 for directed\n",
    "learning_rate = 0.01  # Step size for gradient descent\n",
    "epochs = 10000  # Number of training iterations\n",
    "num_samples = 10  # Total number of graph samples (5 directed, 5 undirected)\n",
    "\n",
    "# Generate the dataset of adjacency matrices and labels\n",
    "X, y = generate_adjacency_matrices(num_samples)\n",
    "\n",
    "# Initialize the neural network with specified architecture\n",
    "nn = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "# Train the network and collect error history\n",
    "errors = nn.train(X, y, epochs, learning_rate)\n",
    "\n",
    "# Plot the mean squared error over training epochs\n",
    "plt.plot(errors)  # Plot error values\n",
    "plt.xlabel('Epoch')  # Label x-axis\n",
    "plt.ylabel('Mean Squared Error')  # Label y-axis\n",
    "plt.title('Training Error vs Epoch')  # Set plot title\n",
    "plt.grid(True)  # Add grid for better readability\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "# Test the trained network on the dataset\n",
    "print(\"\\nTesting network:\")\n",
    "for i in range(num_samples):\n",
    "    # Get prediction for each sample\n",
    "    prediction = nn.forward(X[i:i+1])[0][0]\n",
    "    # Get true label\n",
    "    actual = y[i][0]\n",
    "    # Print predicted and actual values\n",
    "    print(f\"Sample {i+1}: Predicted: {prediction:.3f}, Actual: {actual}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
